{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import sklearn as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Company</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Forward P/E</th>\n",
       "      <th>EPS growth next year</th>\n",
       "      <th>EPS growth past 5 years</th>\n",
       "      <th>EPS growth next 5 years</th>\n",
       "      <th>Sales growth past 5 years</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Total Debt/Equity</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Average True Range</th>\n",
       "      <th>IPO Date</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Analyst Recom</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target Price</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>3048721.25</td>\n",
       "      <td>29.81</td>\n",
       "      <td>10.15</td>\n",
       "      <td>21.6</td>\n",
       "      <td>7.86</td>\n",
       "      <td>11.5</td>\n",
       "      <td>385095.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>24.50</td>\n",
       "      <td>2.90</td>\n",
       "      <td>12/12/1980</td>\n",
       "      <td>164000</td>\n",
       "      <td>BUY</td>\n",
       "      <td>38786913</td>\n",
       "      <td>193.16</td>\n",
       "      <td>196.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>212334.12</td>\n",
       "      <td>25.39</td>\n",
       "      <td>7.42</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8.64</td>\n",
       "      <td>11.2</td>\n",
       "      <td>63550.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.30</td>\n",
       "      <td>5.59</td>\n",
       "      <td>7/19/2001</td>\n",
       "      <td>721000</td>\n",
       "      <td>BUY</td>\n",
       "      <td>1351376</td>\n",
       "      <td>337.95</td>\n",
       "      <td>316.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>241931.46</td>\n",
       "      <td>30.71</td>\n",
       "      <td>13.04</td>\n",
       "      <td>24.5</td>\n",
       "      <td>14.07</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18429.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>26.30</td>\n",
       "      <td>13.98</td>\n",
       "      <td>8/13/1986</td>\n",
       "      <td>29239</td>\n",
       "      <td>BUY</td>\n",
       "      <td>4060003</td>\n",
       "      <td>547.43</td>\n",
       "      <td>546.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ADSK</td>\n",
       "      <td>Autodesk, Inc.</td>\n",
       "      <td>45236.55</td>\n",
       "      <td>25.32</td>\n",
       "      <td>14.92</td>\n",
       "      <td>48.5</td>\n",
       "      <td>14.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.40</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6/28/1985</td>\n",
       "      <td>13700</td>\n",
       "      <td>BUY</td>\n",
       "      <td>1302035</td>\n",
       "      <td>231.70</td>\n",
       "      <td>211.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AI</td>\n",
       "      <td>C3.ai, Inc.</td>\n",
       "      <td>4666.62</td>\n",
       "      <td>358.97</td>\n",
       "      <td>140.00</td>\n",
       "      <td>35.2</td>\n",
       "      <td>12.13</td>\n",
       "      <td>27.3</td>\n",
       "      <td>266.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.05</td>\n",
       "      <td>3.26</td>\n",
       "      <td>12/9/2020</td>\n",
       "      <td>914</td>\n",
       "      <td>HOLD</td>\n",
       "      <td>18445319</td>\n",
       "      <td>28.40</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. Ticker         Company  Market Cap  Forward P/E  EPS growth next year  \\\n",
       "0    1   AAPL      Apple Inc.  3048721.25        29.81                 10.15   \n",
       "1    2    ACN   Accenture plc   212334.12        25.39                  7.42   \n",
       "2    3   ADBE      Adobe Inc.   241931.46        30.71                 13.04   \n",
       "3    4   ADSK  Autodesk, Inc.    45236.55        25.32                 14.92   \n",
       "4    5     AI     C3.ai, Inc.     4666.62       358.97                140.00   \n",
       "\n",
       "   EPS growth past 5 years  EPS growth next 5 years  \\\n",
       "0                     21.6                     7.86   \n",
       "1                     14.5                     8.64   \n",
       "2                     24.5                    14.07   \n",
       "3                     48.5                    14.38   \n",
       "4                     35.2                    12.13   \n",
       "\n",
       "   Sales growth past 5 years     Sales  Total Debt/Equity  Profit Margin  \\\n",
       "0                       11.5  385095.0               1.76          24.50   \n",
       "1                       11.2   63550.2               0.00          11.30   \n",
       "2                       19.2   18429.0               0.24          26.30   \n",
       "3                       19.5    5104.0               0.00          16.40   \n",
       "4                       27.3     266.8               0.00           9.05   \n",
       "\n",
       "   Average True Range    IPO Date  Employees Analyst Recom    Volume  \\\n",
       "0                2.90  12/12/1980     164000           BUY  38786913   \n",
       "1                5.59   7/19/2001     721000           BUY   1351376   \n",
       "2               13.98   8/13/1986      29239           BUY   4060003   \n",
       "3                5.61   6/28/1985      13700           BUY   1302035   \n",
       "4                3.26   12/9/2020        914          HOLD  18445319   \n",
       "\n",
       "   Target Price   Price  \n",
       "0        193.16  196.45  \n",
       "1        337.95  316.35  \n",
       "2        547.43  546.17  \n",
       "3        231.70  211.99  \n",
       "4         28.40   42.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data = Path('AI_Stocks.csv')\n",
    "stock_df = pd.read_csv(stock_data)\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Forward P/E</th>\n",
       "      <th>EPS growth next year</th>\n",
       "      <th>EPS growth past 5 years</th>\n",
       "      <th>EPS growth next 5 years</th>\n",
       "      <th>Sales growth past 5 years</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Total Debt/Equity</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Average True Range</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Analyst Recom</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target Price</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3048721.25</td>\n",
       "      <td>29.81</td>\n",
       "      <td>10.15</td>\n",
       "      <td>21.6</td>\n",
       "      <td>7.86</td>\n",
       "      <td>11.5</td>\n",
       "      <td>385095.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>24.50</td>\n",
       "      <td>2.90</td>\n",
       "      <td>164000</td>\n",
       "      <td>BUY</td>\n",
       "      <td>38786913</td>\n",
       "      <td>193.16</td>\n",
       "      <td>196.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212334.12</td>\n",
       "      <td>25.39</td>\n",
       "      <td>7.42</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8.64</td>\n",
       "      <td>11.2</td>\n",
       "      <td>63550.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.30</td>\n",
       "      <td>5.59</td>\n",
       "      <td>721000</td>\n",
       "      <td>BUY</td>\n",
       "      <td>1351376</td>\n",
       "      <td>337.95</td>\n",
       "      <td>316.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241931.46</td>\n",
       "      <td>30.71</td>\n",
       "      <td>13.04</td>\n",
       "      <td>24.5</td>\n",
       "      <td>14.07</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18429.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>26.30</td>\n",
       "      <td>13.98</td>\n",
       "      <td>29239</td>\n",
       "      <td>BUY</td>\n",
       "      <td>4060003</td>\n",
       "      <td>547.43</td>\n",
       "      <td>546.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45236.55</td>\n",
       "      <td>25.32</td>\n",
       "      <td>14.92</td>\n",
       "      <td>48.5</td>\n",
       "      <td>14.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.40</td>\n",
       "      <td>5.61</td>\n",
       "      <td>13700</td>\n",
       "      <td>BUY</td>\n",
       "      <td>1302035</td>\n",
       "      <td>231.70</td>\n",
       "      <td>211.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4666.62</td>\n",
       "      <td>358.97</td>\n",
       "      <td>140.00</td>\n",
       "      <td>35.2</td>\n",
       "      <td>12.13</td>\n",
       "      <td>27.3</td>\n",
       "      <td>266.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.05</td>\n",
       "      <td>3.26</td>\n",
       "      <td>914</td>\n",
       "      <td>HOLD</td>\n",
       "      <td>18445319</td>\n",
       "      <td>28.40</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Market Cap  Forward P/E  EPS growth next year  EPS growth past 5 years  \\\n",
       "0  3048721.25        29.81                 10.15                     21.6   \n",
       "1   212334.12        25.39                  7.42                     14.5   \n",
       "2   241931.46        30.71                 13.04                     24.5   \n",
       "3    45236.55        25.32                 14.92                     48.5   \n",
       "4     4666.62       358.97                140.00                     35.2   \n",
       "\n",
       "   EPS growth next 5 years  Sales growth past 5 years     Sales  \\\n",
       "0                     7.86                       11.5  385095.0   \n",
       "1                     8.64                       11.2   63550.2   \n",
       "2                    14.07                       19.2   18429.0   \n",
       "3                    14.38                       19.5    5104.0   \n",
       "4                    12.13                       27.3     266.8   \n",
       "\n",
       "   Total Debt/Equity  Profit Margin  Average True Range  Employees  \\\n",
       "0               1.76          24.50                2.90     164000   \n",
       "1               0.00          11.30                5.59     721000   \n",
       "2               0.24          26.30               13.98      29239   \n",
       "3               0.00          16.40                5.61      13700   \n",
       "4               0.00           9.05                3.26        914   \n",
       "\n",
       "  Analyst Recom    Volume  Target Price   Price  \n",
       "0           BUY  38786913        193.16  196.45  \n",
       "1           BUY   1351376        337.95  316.35  \n",
       "2           BUY   4060003        547.43  546.17  \n",
       "3           BUY   1302035        231.70  211.99  \n",
       "4          HOLD  18445319         28.40   42.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df1 = stock_df.drop(columns=['No.', 'Ticker', 'Company', 'IPO Date'])\n",
    "stock_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Forward P/E</th>\n",
       "      <th>EPS growth next year</th>\n",
       "      <th>EPS growth past 5 years</th>\n",
       "      <th>EPS growth next 5 years</th>\n",
       "      <th>Sales growth past 5 years</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Total Debt/Equity</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Average True Range</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Analyst Recom_BUY</th>\n",
       "      <th>Analyst Recom_HOLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3048721.25</td>\n",
       "      <td>29.8100</td>\n",
       "      <td>10.15</td>\n",
       "      <td>21.60</td>\n",
       "      <td>7.86</td>\n",
       "      <td>11.50</td>\n",
       "      <td>385095.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>24.50</td>\n",
       "      <td>2.90</td>\n",
       "      <td>164000</td>\n",
       "      <td>38786913</td>\n",
       "      <td>193.16</td>\n",
       "      <td>196.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212334.12</td>\n",
       "      <td>25.3900</td>\n",
       "      <td>7.42</td>\n",
       "      <td>14.50</td>\n",
       "      <td>8.64</td>\n",
       "      <td>11.20</td>\n",
       "      <td>63550.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.30</td>\n",
       "      <td>5.59</td>\n",
       "      <td>721000</td>\n",
       "      <td>1351376</td>\n",
       "      <td>337.95</td>\n",
       "      <td>316.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241931.46</td>\n",
       "      <td>30.7100</td>\n",
       "      <td>13.04</td>\n",
       "      <td>24.50</td>\n",
       "      <td>14.07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>18429.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>26.30</td>\n",
       "      <td>13.98</td>\n",
       "      <td>29239</td>\n",
       "      <td>4060003</td>\n",
       "      <td>547.43</td>\n",
       "      <td>546.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45236.55</td>\n",
       "      <td>25.3200</td>\n",
       "      <td>14.92</td>\n",
       "      <td>48.50</td>\n",
       "      <td>14.38</td>\n",
       "      <td>19.50</td>\n",
       "      <td>5104.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.40</td>\n",
       "      <td>5.61</td>\n",
       "      <td>13700</td>\n",
       "      <td>1302035</td>\n",
       "      <td>231.70</td>\n",
       "      <td>211.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4666.62</td>\n",
       "      <td>358.9700</td>\n",
       "      <td>140.00</td>\n",
       "      <td>35.20</td>\n",
       "      <td>12.13</td>\n",
       "      <td>27.30</td>\n",
       "      <td>266.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.05</td>\n",
       "      <td>3.26</td>\n",
       "      <td>914</td>\n",
       "      <td>18445319</td>\n",
       "      <td>28.40</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>181192.44</td>\n",
       "      <td>26.9900</td>\n",
       "      <td>48.95</td>\n",
       "      <td>21.90</td>\n",
       "      <td>9.87</td>\n",
       "      <td>35.10</td>\n",
       "      <td>23067.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4.21</td>\n",
       "      <td>25000</td>\n",
       "      <td>54041667</td>\n",
       "      <td>133.65</td>\n",
       "      <td>114.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1330520.98</td>\n",
       "      <td>51.7700</td>\n",
       "      <td>62.19</td>\n",
       "      <td>-26.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>23.60</td>\n",
       "      <td>524897.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1541000</td>\n",
       "      <td>41832022</td>\n",
       "      <td>143.17</td>\n",
       "      <td>133.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29304.29</td>\n",
       "      <td>35.3600</td>\n",
       "      <td>11.63</td>\n",
       "      <td>13.60</td>\n",
       "      <td>8.30</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2149.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.70</td>\n",
       "      <td>7.19</td>\n",
       "      <td>5600</td>\n",
       "      <td>398081</td>\n",
       "      <td>338.36</td>\n",
       "      <td>342.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>290876.78</td>\n",
       "      <td>29.5800</td>\n",
       "      <td>14.10</td>\n",
       "      <td>24.20</td>\n",
       "      <td>21.67</td>\n",
       "      <td>18.80</td>\n",
       "      <td>28372.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.70</td>\n",
       "      <td>19.53</td>\n",
       "      <td>38866</td>\n",
       "      <td>789125</td>\n",
       "      <td>758.86</td>\n",
       "      <td>716.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>368275.77</td>\n",
       "      <td>19.9100</td>\n",
       "      <td>7.61</td>\n",
       "      <td>45.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>13.50</td>\n",
       "      <td>35042.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>38.70</td>\n",
       "      <td>19.55</td>\n",
       "      <td>20000</td>\n",
       "      <td>1495229</td>\n",
       "      <td>880.43</td>\n",
       "      <td>898.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>289.04</td>\n",
       "      <td>17.1250</td>\n",
       "      <td>28.60</td>\n",
       "      <td>14.05</td>\n",
       "      <td>12.41</td>\n",
       "      <td>10.65</td>\n",
       "      <td>160.8</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-80.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>649</td>\n",
       "      <td>3777775</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>51960.27</td>\n",
       "      <td>14.3400</td>\n",
       "      <td>12.90</td>\n",
       "      <td>-17.70</td>\n",
       "      <td>14.21</td>\n",
       "      <td>7.80</td>\n",
       "      <td>17622.8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.80</td>\n",
       "      <td>5.43</td>\n",
       "      <td>41300</td>\n",
       "      <td>2862495</td>\n",
       "      <td>180.18</td>\n",
       "      <td>155.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>218723.22</td>\n",
       "      <td>25.0400</td>\n",
       "      <td>20.68</td>\n",
       "      <td>-20.60</td>\n",
       "      <td>25.12</td>\n",
       "      <td>24.40</td>\n",
       "      <td>32188.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.93</td>\n",
       "      <td>79390</td>\n",
       "      <td>5572443</td>\n",
       "      <td>240.97</td>\n",
       "      <td>225.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37653.85</td>\n",
       "      <td>52.4900</td>\n",
       "      <td>28.92</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>38.80</td>\n",
       "      <td>80.00</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>5.62</td>\n",
       "      <td>7321</td>\n",
       "      <td>3915877</td>\n",
       "      <td>178.05</td>\n",
       "      <td>161.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1667240.60</td>\n",
       "      <td>20.1400</td>\n",
       "      <td>18.23</td>\n",
       "      <td>23.30</td>\n",
       "      <td>16.20</td>\n",
       "      <td>20.60</td>\n",
       "      <td>289531.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.10</td>\n",
       "      <td>3.45</td>\n",
       "      <td>181798</td>\n",
       "      <td>28039815</td>\n",
       "      <td>146.25</td>\n",
       "      <td>132.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>130909.67</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>5.25</td>\n",
       "      <td>-29.90</td>\n",
       "      <td>4.55</td>\n",
       "      <td>-5.20</td>\n",
       "      <td>60524.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.84</td>\n",
       "      <td>311300</td>\n",
       "      <td>6138696</td>\n",
       "      <td>143.75</td>\n",
       "      <td>144.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>139960.50</td>\n",
       "      <td>20.5100</td>\n",
       "      <td>201.73</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.10</td>\n",
       "      <td>56416.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.14</td>\n",
       "      <td>131900</td>\n",
       "      <td>55532825</td>\n",
       "      <td>34.51</td>\n",
       "      <td>35.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>781943.18</td>\n",
       "      <td>19.6000</td>\n",
       "      <td>25.60</td>\n",
       "      <td>8.20</td>\n",
       "      <td>30.83</td>\n",
       "      <td>23.50</td>\n",
       "      <td>120523.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>18.70</td>\n",
       "      <td>10.19</td>\n",
       "      <td>71469</td>\n",
       "      <td>25740755</td>\n",
       "      <td>359.41</td>\n",
       "      <td>318.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2440112.90</td>\n",
       "      <td>26.4500</td>\n",
       "      <td>15.06</td>\n",
       "      <td>20.00</td>\n",
       "      <td>14.41</td>\n",
       "      <td>13.90</td>\n",
       "      <td>211915.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>34.10</td>\n",
       "      <td>8.86</td>\n",
       "      <td>221000</td>\n",
       "      <td>25424586</td>\n",
       "      <td>384.31</td>\n",
       "      <td>335.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5565.45</td>\n",
       "      <td>27.5000</td>\n",
       "      <td>-106.10</td>\n",
       "      <td>85.19</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>501.9</td>\n",
       "      <td>4.91</td>\n",
       "      <td>9.05</td>\n",
       "      <td>20.69</td>\n",
       "      <td>2123</td>\n",
       "      <td>486429</td>\n",
       "      <td>426.00</td>\n",
       "      <td>437.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>78050.69</td>\n",
       "      <td>37.6550</td>\n",
       "      <td>76.60</td>\n",
       "      <td>11.90</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.60</td>\n",
       "      <td>18173.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>1.91</td>\n",
       "      <td>48000</td>\n",
       "      <td>11188512</td>\n",
       "      <td>74.76</td>\n",
       "      <td>71.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>670.28</td>\n",
       "      <td>39.3325</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-41.40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>350</td>\n",
       "      <td>4555487</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>188765.88</td>\n",
       "      <td>28.5500</td>\n",
       "      <td>29.30</td>\n",
       "      <td>44.90</td>\n",
       "      <td>24.17</td>\n",
       "      <td>22.00</td>\n",
       "      <td>32126.5</td>\n",
       "      <td>0.63</td>\n",
       "      <td>13.20</td>\n",
       "      <td>14.30</td>\n",
       "      <td>12800</td>\n",
       "      <td>6578026</td>\n",
       "      <td>463.39</td>\n",
       "      <td>438.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>116769.07</td>\n",
       "      <td>47.8100</td>\n",
       "      <td>23.04</td>\n",
       "      <td>34.10</td>\n",
       "      <td>25.67</td>\n",
       "      <td>30.40</td>\n",
       "      <td>8017.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>15.87</td>\n",
       "      <td>20433</td>\n",
       "      <td>1669959</td>\n",
       "      <td>631.43</td>\n",
       "      <td>583.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1133220.33</td>\n",
       "      <td>41.0100</td>\n",
       "      <td>43.57</td>\n",
       "      <td>8.60</td>\n",
       "      <td>21.20</td>\n",
       "      <td>22.70</td>\n",
       "      <td>25878.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>18.50</td>\n",
       "      <td>14.56</td>\n",
       "      <td>26196</td>\n",
       "      <td>25057210</td>\n",
       "      <td>499.98</td>\n",
       "      <td>467.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>319316.94</td>\n",
       "      <td>18.6200</td>\n",
       "      <td>12.57</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11.46</td>\n",
       "      <td>4.90</td>\n",
       "      <td>49954.0</td>\n",
       "      <td>84.33</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>164000</td>\n",
       "      <td>6703090</td>\n",
       "      <td>124.89</td>\n",
       "      <td>117.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9738.25</td>\n",
       "      <td>45.8900</td>\n",
       "      <td>15.54</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>31.70</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1103.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-21.50</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3833</td>\n",
       "      <td>6897426</td>\n",
       "      <td>18.53</td>\n",
       "      <td>18.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38094.39</td>\n",
       "      <td>78.1100</td>\n",
       "      <td>18.69</td>\n",
       "      <td>6.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>15.85</td>\n",
       "      <td>1984.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-12.90</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3850</td>\n",
       "      <td>141774559</td>\n",
       "      <td>11.61</td>\n",
       "      <td>19.84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4644.76</td>\n",
       "      <td>49.1900</td>\n",
       "      <td>93.20</td>\n",
       "      <td>12.79</td>\n",
       "      <td>47.70</td>\n",
       "      <td>19.11</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-82.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2200</td>\n",
       "      <td>8682738</td>\n",
       "      <td>18.19</td>\n",
       "      <td>16.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>167315.09</td>\n",
       "      <td>20.2600</td>\n",
       "      <td>18.70</td>\n",
       "      <td>-10.20</td>\n",
       "      <td>21.20</td>\n",
       "      <td>5.60</td>\n",
       "      <td>34314.7</td>\n",
       "      <td>0.26</td>\n",
       "      <td>16.40</td>\n",
       "      <td>2.44</td>\n",
       "      <td>105328</td>\n",
       "      <td>828453</td>\n",
       "      <td>152.13</td>\n",
       "      <td>136.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>55745.85</td>\n",
       "      <td>180.2300</td>\n",
       "      <td>61.11</td>\n",
       "      <td>14.85</td>\n",
       "      <td>15.94</td>\n",
       "      <td>26.45</td>\n",
       "      <td>2266.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-37.80</td>\n",
       "      <td>7.76</td>\n",
       "      <td>5884</td>\n",
       "      <td>3481372</td>\n",
       "      <td>200.16</td>\n",
       "      <td>177.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>468.70</td>\n",
       "      <td>431.7300</td>\n",
       "      <td>48.70</td>\n",
       "      <td>19.58</td>\n",
       "      <td>10.97</td>\n",
       "      <td>22.38</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-20.05</td>\n",
       "      <td>0.39</td>\n",
       "      <td>430</td>\n",
       "      <td>15763269</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33040.80</td>\n",
       "      <td>683.2300</td>\n",
       "      <td>123.70</td>\n",
       "      <td>-12.41</td>\n",
       "      <td>26.95</td>\n",
       "      <td>23.39</td>\n",
       "      <td>893.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>5.89</td>\n",
       "      <td>1120</td>\n",
       "      <td>5828962</td>\n",
       "      <td>42.33</td>\n",
       "      <td>63.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>814637.22</td>\n",
       "      <td>56.7100</td>\n",
       "      <td>37.21</td>\n",
       "      <td>39.90</td>\n",
       "      <td>10.68</td>\n",
       "      <td>47.30</td>\n",
       "      <td>94028.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.89</td>\n",
       "      <td>127855</td>\n",
       "      <td>84439847</td>\n",
       "      <td>235.79</td>\n",
       "      <td>267.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>464939.14</td>\n",
       "      <td>15.8100</td>\n",
       "      <td>23.40</td>\n",
       "      <td>24.30</td>\n",
       "      <td>6.00</td>\n",
       "      <td>18.30</td>\n",
       "      <td>71152.8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>45.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>52045</td>\n",
       "      <td>8651202</td>\n",
       "      <td>112.01</td>\n",
       "      <td>99.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25599.10</td>\n",
       "      <td>18.9900</td>\n",
       "      <td>129.81</td>\n",
       "      <td>-44.40</td>\n",
       "      <td>42.92</td>\n",
       "      <td>24.40</td>\n",
       "      <td>5349.9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-21.00</td>\n",
       "      <td>2.62</td>\n",
       "      <td>11580</td>\n",
       "      <td>1043172</td>\n",
       "      <td>152.12</td>\n",
       "      <td>152.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>162844.20</td>\n",
       "      <td>22.7000</td>\n",
       "      <td>7.96</td>\n",
       "      <td>20.80</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>18821.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>40.60</td>\n",
       "      <td>4.10</td>\n",
       "      <td>33000</td>\n",
       "      <td>4065205</td>\n",
       "      <td>183.94</td>\n",
       "      <td>180.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5135.26</td>\n",
       "      <td>106.1700</td>\n",
       "      <td>266.70</td>\n",
       "      <td>-65.30</td>\n",
       "      <td>30.00</td>\n",
       "      <td>77.70</td>\n",
       "      <td>710.4</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-38.10</td>\n",
       "      <td>5.06</td>\n",
       "      <td>1875</td>\n",
       "      <td>12278567</td>\n",
       "      <td>22.93</td>\n",
       "      <td>68.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>33047.49</td>\n",
       "      <td>35.5500</td>\n",
       "      <td>16.48</td>\n",
       "      <td>18.90</td>\n",
       "      <td>10.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2373.1</td>\n",
       "      <td>41.53</td>\n",
       "      <td>21.30</td>\n",
       "      <td>3.71</td>\n",
       "      <td>7000</td>\n",
       "      <td>1511787</td>\n",
       "      <td>232.79</td>\n",
       "      <td>228.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Market Cap  Forward P/E  EPS growth next year  EPS growth past 5 years  \\\n",
       "0   3048721.25      29.8100                 10.15                    21.60   \n",
       "1    212334.12      25.3900                  7.42                    14.50   \n",
       "2    241931.46      30.7100                 13.04                    24.50   \n",
       "3     45236.55      25.3200                 14.92                    48.50   \n",
       "4      4666.62     358.9700                140.00                    35.20   \n",
       "5    181192.44      26.9900                 48.95                    21.90   \n",
       "6   1330520.98      51.7700                 62.19                   -26.00   \n",
       "7     29304.29      35.3600                 11.63                    13.60   \n",
       "8    290876.78      29.5800                 14.10                    24.20   \n",
       "9    368275.77      19.9100                  7.61                    45.80   \n",
       "10      289.04      17.1250                 28.60                    14.05   \n",
       "11    51960.27      14.3400                 12.90                   -17.70   \n",
       "12   218723.22      25.0400                 20.68                   -20.60   \n",
       "13    37653.85      52.4900                 28.92                    -1.80   \n",
       "14  1667240.60      20.1400                 18.23                    23.30   \n",
       "15   130909.67      14.3000                  5.25                   -29.90   \n",
       "16   139960.50      20.5100                201.73                    -8.90   \n",
       "17   781943.18      19.6000                 25.60                     8.20   \n",
       "18  2440112.90      26.4500                 15.06                    20.00   \n",
       "19     5565.45      27.5000               -106.10                    85.19   \n",
       "20    78050.69      37.6550                 76.60                    11.90   \n",
       "21      670.28      39.3325                 18.90                     1.80   \n",
       "22   188765.88      28.5500                 29.30                    44.90   \n",
       "23   116769.07      47.8100                 23.04                    34.10   \n",
       "24  1133220.33      41.0100                 43.57                     8.60   \n",
       "25   319316.94      18.6200                 12.57                     4.50   \n",
       "26     9738.25      45.8900                 15.54                    -2.85   \n",
       "27    38094.39      78.1100                 18.69                     6.00   \n",
       "28     4644.76      49.1900                 93.20                    12.79   \n",
       "29   167315.09      20.2600                 18.70                   -10.20   \n",
       "30    55745.85     180.2300                 61.11                    14.85   \n",
       "31      468.70     431.7300                 48.70                    19.58   \n",
       "32    33040.80     683.2300                123.70                   -12.41   \n",
       "33   814637.22      56.7100                 37.21                    39.90   \n",
       "34   464939.14      15.8100                 23.40                    24.30   \n",
       "35    25599.10      18.9900                129.81                   -44.40   \n",
       "36   162844.20      22.7000                  7.96                    20.80   \n",
       "37     5135.26     106.1700                266.70                   -65.30   \n",
       "38    33047.49      35.5500                 16.48                    18.90   \n",
       "\n",
       "    EPS growth next 5 years  Sales growth past 5 years     Sales  \\\n",
       "0                      7.86                      11.50  385095.0   \n",
       "1                      8.64                      11.20   63550.2   \n",
       "2                     14.07                      19.20   18429.0   \n",
       "3                     14.38                      19.50    5104.0   \n",
       "4                     12.13                      27.30     266.8   \n",
       "5                      9.87                      35.10   23067.0   \n",
       "6                      9.09                      23.60  524897.0   \n",
       "7                      8.30                      13.50    2149.9   \n",
       "8                     21.67                      18.80   28372.8   \n",
       "9                     10.60                      13.50   35042.0   \n",
       "10                    12.41                      10.65     160.8   \n",
       "11                    14.21                       7.80   17622.8   \n",
       "12                    25.12                      24.40   32188.0   \n",
       "13                    38.80                      80.00    2446.0   \n",
       "14                    16.20                      20.60  289531.0   \n",
       "15                     4.55                      -5.20   60524.0   \n",
       "16                     6.71                       0.10   56416.0   \n",
       "17                    30.83                      23.50  120523.0   \n",
       "18                    14.41                      13.90  211915.0   \n",
       "19                    10.00                      -0.20     501.9   \n",
       "20                    10.00                       8.60   18173.0   \n",
       "21                    10.00                     -41.40       1.1   \n",
       "22                    24.17                      22.00   32126.5   \n",
       "23                    25.67                      30.40    8017.0   \n",
       "24                    21.20                      22.70   25878.0   \n",
       "25                    11.46                       4.90   49954.0   \n",
       "26                    31.70                       5.25    1103.1   \n",
       "27                    73.00                      15.85    1984.7   \n",
       "28                    47.70                      19.11     477.3   \n",
       "29                    21.20                       5.60   34314.7   \n",
       "30                    15.94                      26.45    2266.9   \n",
       "31                    10.97                      22.38      33.5   \n",
       "32                    26.95                      23.39     893.1   \n",
       "33                    10.68                      47.30   94028.0   \n",
       "34                     6.00                      18.30   71152.8   \n",
       "35                    42.92                      24.40    5349.9   \n",
       "36                    10.00                       6.00   18821.0   \n",
       "37                    30.00                      77.70     710.4   \n",
       "38                    10.50                       3.10    2373.1   \n",
       "\n",
       "    Total Debt/Equity  Profit Margin  Average True Range  Employees  \\\n",
       "0                1.76          24.50                2.90     164000   \n",
       "1                0.00          11.30                5.59     721000   \n",
       "2                0.24          26.30               13.98      29239   \n",
       "3                0.00          16.40                5.61      13700   \n",
       "4                0.00           9.05                3.26        914   \n",
       "5                0.00           1.70                4.21      25000   \n",
       "6                0.56           0.80                3.17    1541000   \n",
       "7                0.00          25.70                7.19       5600   \n",
       "8                0.00          28.70               19.53      38866   \n",
       "9                1.79          38.70               19.55      20000   \n",
       "10               1.09         -80.30                0.16        649   \n",
       "11               0.38          10.80                5.43      41300   \n",
       "12               0.17           1.20                4.93      79390   \n",
       "13               0.46          -6.20                5.62       7321   \n",
       "14               0.05          21.10                3.45     181798   \n",
       "15               2.59           3.30                1.84     311300   \n",
       "16               0.51          14.20                1.14     131900   \n",
       "17               0.15          18.70               10.19      71469   \n",
       "18               0.31          34.10                8.86     221000   \n",
       "19               4.91           9.05               20.69       2123   \n",
       "20               0.29         -16.00                1.91      48000   \n",
       "21               0.00          -1.40                0.32        350   \n",
       "22               0.63          13.20               14.30      12800   \n",
       "23               0.00          17.80               15.87      20433   \n",
       "24               0.45          18.50               14.56      26196   \n",
       "25              84.33          17.00                2.45     164000   \n",
       "26               0.00         -21.50                0.87       3833   \n",
       "27               0.00         -12.90                1.05       3850   \n",
       "28               0.00         -82.90                0.81       2200   \n",
       "29               0.26          16.40                2.44     105328   \n",
       "30               0.00         -37.80                7.76       5884   \n",
       "31               0.00         -20.05                0.39        430   \n",
       "32               0.00          -2.30                5.89       1120   \n",
       "33               0.05          13.00               10.89     127855   \n",
       "34               0.29          45.60                2.51      52045   \n",
       "35               0.34         -21.00                2.62      11580   \n",
       "36               0.70          40.60                4.10      33000   \n",
       "37               1.60         -38.10                5.06       1875   \n",
       "38              41.53          21.30                3.71       7000   \n",
       "\n",
       "       Volume  Target Price   Price  Analyst Recom_BUY  Analyst Recom_HOLD  \n",
       "0    38786913        193.16  196.45                  1                   0  \n",
       "1     1351376        337.95  316.35                  1                   0  \n",
       "2     4060003        547.43  546.17                  1                   0  \n",
       "3     1302035        231.70  211.99                  1                   0  \n",
       "4    18445319         28.40   42.00                  0                   1  \n",
       "5    54041667        133.65  114.40                  1                   0  \n",
       "6    41832022        143.17  133.68                  1                   0  \n",
       "7      398081        338.36  342.10                  1                   0  \n",
       "8      789125        758.86  716.41                  1                   0  \n",
       "9     1495229        880.43  898.65                  1                   0  \n",
       "10    3777775          5.00    2.01                  1                   0  \n",
       "11    2862495        180.18  155.99                  1                   0  \n",
       "12    5572443        240.97  225.01                  1                   0  \n",
       "13    3915877        178.05  161.66                  1                   0  \n",
       "14   28039815        146.25  132.72                  1                   0  \n",
       "15    6138696        143.75  144.18                  1                   0  \n",
       "16   55532825         34.51   35.77                  0                   1  \n",
       "17   25740755        359.41  318.60                  1                   0  \n",
       "18   25424586        384.31  335.92                  1                   0  \n",
       "19     486429        426.00  437.88                  1                   0  \n",
       "20   11188512         74.76   71.39                  1                   0  \n",
       "21    4555487          4.00    4.00                  0                   1  \n",
       "22    6578026        463.39  438.97                  1                   0  \n",
       "23    1669959        631.43  583.00                  1                   0  \n",
       "24   25057210        499.98  467.29                  1                   0  \n",
       "25    6703090        124.89  117.23                  1                   0  \n",
       "26    6897426         18.53   18.08                  1                   0  \n",
       "27  141774559         11.61   19.84                  0                   1  \n",
       "28    8682738         18.19   16.67                  1                   0  \n",
       "29     828453        152.13  136.35                  1                   0  \n",
       "30    3481372        200.16  177.71                  1                   0  \n",
       "31   15763269          5.90    2.33                  1                   0  \n",
       "32    5828962         42.33   63.54                  1                   0  \n",
       "33   84439847        235.79  267.43                  1                   0  \n",
       "34    8651202        112.01   99.15                  1                   0  \n",
       "35    1043172        152.12  152.94                  1                   0  \n",
       "36    4065205        183.94  180.00                  1                   0  \n",
       "37   12278567         22.93   68.69                  0                   1  \n",
       "38    1511787        232.79  228.94                  1                   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df2 = pd.get_dummies(stock_df1, columns=[\"Analyst Recom\"])\n",
    "stock_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stock_df2.drop(columns=['Analyst Recom_BUY'])\n",
    "y = stock_df2['Analyst Recom_BUY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     0\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    0\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "20    1\n",
       "21    0\n",
       "22    1\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    1\n",
       "27    0\n",
       "28    1\n",
       "29    1\n",
       "30    1\n",
       "31    1\n",
       "32    1\n",
       "33    1\n",
       "34    1\n",
       "35    1\n",
       "36    1\n",
       "37    0\n",
       "38    1\n",
       "Name: Analyst Recom_BUY, dtype: uint8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Market Cap', 'Forward P/E', 'EPS growth next year',\n",
       "       'EPS growth past 5 years', 'EPS growth next 5 years',\n",
       "       'Sales growth past 5 years', 'Sales', 'Total Debt/Equity',\n",
       "       'Profit Margin', 'Average True Range', 'Employees', 'Volume',\n",
       "       'Target Price', 'Price', 'Analyst Recom_HOLD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit/train the scaler\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=10000, penalty='l1', random_state=1,\n",
       "                     solver='saga')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a logistic regression model\n",
    "#model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "classifier = LogisticRegressionCV(cv=5, penalty='l1', solver='saga', \n",
    "            max_iter=10000, random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soobi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=10000, penalty='l1', random_state=1,\n",
       "                     solver='saga')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8620689655172413\n",
      "Testing Data Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           1       1\n",
       "1           1       1\n",
       "2           1       1\n",
       "3           1       1\n",
       "4           1       0\n",
       "5           1       1\n",
       "6           1       1\n",
       "7           1       1\n",
       "8           1       1\n",
       "9           1       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Display the accuracy score for the test dataset.\n",
    "score = balanced_accuracy_score(y_test, predictions)\n",
    "print('Accuracy score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.45      0.50      0.47        10\n",
      "weighted avg       0.81      0.90      0.85        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soobi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\soobi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\soobi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25\n",
       "0    25\n",
       "Name: Analyst Recom_BUY, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement random oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resample, y_resample = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resample)\n",
    "y_resample.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=10000, penalty='l1', random_state=1,\n",
       "                     solver='saga')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1 = LogisticRegressionCV(cv=5, penalty='l1', solver='saga', \n",
    "            max_iter=10000, random_state=1)\n",
    "classifier1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=10000, penalty='l1', random_state=1,\n",
       "                     solver='saga')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the resampled training data\n",
    "classifier1.fit(X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "18           1       1\n",
       "1            1       1\n",
       "0            1       1\n",
       "17           1       1\n",
       "27           0       0\n",
       "8            1       1\n",
       "12           1       1\n",
       "6            1       1\n",
       "13           0       1\n",
       "10           0       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction using the testing data\n",
    "predictions1= classifier1.predict(X_test)\n",
    "pd.DataFrame({\"Prediction\": predictions1, \"Actual\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy score:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model \n",
    "score1 = balanced_accuracy_score(y_test, predictions1)\n",
    "print('New accuracy score: ', score1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         1\n",
      "           1       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.67      0.89      0.69        10\n",
      "weighted avg       0.93      0.80      0.84        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to curent directory\n",
    "filename = 'classifier1.pkl'\n",
    "pickle.dump(classifier1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, max_iter=10000, penalty=&#x27;l1&#x27;, random_state=1,\n",
       "                     solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=10000, penalty='l1', random_state=1,\n",
       "                     solver='saga')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
